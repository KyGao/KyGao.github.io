<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Home page of Kaiyuan Gao">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Kaiyuan Gao</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Kaiyuan Gao (高开元)&nbsp;</h1></div>
        <h3>Ph.D. Student</h3>
        <br>
        <p>
            Huazhong University of Science and Technology <br>
            Joint Ph.D. at Microsoft Research AI4Science <br>
            Email: im_kai[AT]hust[DOT]edu.cn <br>
            <a href="https://scholar.google.com/citations?user=Or77MPQAAAAJ">[Google Scholar]</a > 
            <a href="./files/gaokaiyuan_cv.pdf">[CV]</a > <br>
        </p >
    </td>

    <td>< img src="./files/profile_gky.jpg" border="0" width="200"></td>
</tr></tbody></table>


<h2>Biography</h2>
    <p> 
        I am a final-year Ph.D. Candidate in a joint program between <a href="https://www.hust.edu.cn">Huazhong University of Science and Technology</a > and <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia">Microsoft Research Asia</a >, advised by <a href="https://scholar.google.com/citations?user=YTQnGJsAAAAJ">Prof. Kun He</a > and <a href="https://scholar.google.com/citations?user=Nh832fgAAAAJ">Dr. Tie-Yan Liu</a >. Previously, I received my B.S. degree from the Department of <a href="https://aia.hust.edu.cn">Aritificial Intelligence and Automation</a > of Huazhong University of Science and Technology in July 2021.
    </p >

    <p>
        During my time at Microsoft Research, I worked on <strong>3D molecular structure modeling</strong> and molecule generation using diffusion and language models, with in-depth research on molecular docking. Currently, I am a core contributor to the <a href="https://github.com/QwenLM/Qwen-Image"><strong>Qwen-Image</strong></a > project, where I actively contribute to research on image editing and the development of <strong>visual generation</strong> within the Qwen team.
    </p >

    <p>
          <font color="#FF0000">Looking for industrial research positions. Expect to graduate in June 2026.</font> Drop me an email if you feel interested.
    </p >

<h2>Selected Publications</h2>
<strong> Visual Generation: </strong>
<ul>
    <li>
        <a href='https://arxiv.org/abs/2508.02324'> Qwen-Image Technical Report </a > <br>
        Chenfei Wu, Jiahao Li, Jingren Zhou, Junyang Lin, <strong>Kaiyuan Gao</strong>, Kun Yan, Sheng-ming Yin, Shuai Bai, Xiao Xu, Yilei Chen, Yuxiang Chen, Zecheng Tang, Zekai Zhang, Zhengyi Wang, An Yang, Bowen Yu, Chen Cheng, Dayiheng Liu, Deqing Li, Hang Zhang, Hao Meng, Hu Wei, Jingyuan Ni, Kai Chen, Kuan Cao, Liang Peng, Lin Qu, Minggang Wu, Peng Wang, Shuting Yu, Tingkun Wen, Wensen Feng, Xiaoxiao Xu, Yi Wang, Yichang Zhang, Yongqiang Zhu, Yujia Wu, Yuxuan Cai, Zenan Liu<br>
        <a href='https://github.com/QwenLM/Qwen-Image'>[Code: <font color="#FF0000">4.2k Stars</font>]</a >        
        <a href='https://huggingface.co/Qwen/Qwen-Image'>[Text-to-Image Model: <font color="#FF0000">144k Downloads</font>]</a >
        <a href='https://huggingface.co/Qwen/Qwen-Image-Edit'>[Image Edit Model: <font color="#FF0000">28k Downloads</font>]</a >
    </li>
</ul>

<strong> 3D Molecular Structure Modeling: </strong>
<ul>
    <li>
        <a href='https://proceedings.neurips.cc/paper_files/paper/2023/hash/aee1de5f335558b546b7e58c380be087-Abstract-Conference.html'> Fabind: Fast and accurate protein-ligand binding </a > <br>
        Qizhi Pei*, <strong>Kaiyuan Gao*</strong>, Lijun Wu, Jinhua Zhu, Yingce Xia, Shufang Xie, Tao Qin, Kun He, Tie-Yan Liu, Rui Yan<br>
        Advances in Neural Information Processing Systems <strong>(NeurIPS 2023)</strong><br>
        <a href='https://github.com/QizhiPei/FABind'>[Code: <font color="#FF0000">134 Stars</font>]</a >        
        <a href="https://huggingface.co/QizhiPei/FABind_model">[Weights]</a>
    </li>

    <li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3690624.3709253'> FABind+: Enhancing Molecular Docking through Improved Pocket Prediction and Pose Generation </a > <br>
        <strong>Kaiyuan Gao</strong>, Qizhi Pei, Gongbo Zhang, Jinhua Zhu, Kun He, Lijun Wu<br>
        ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2025)</strong><br>
        <a href='https://github.com/QizhiPei/FABind'>[Code: <font color="#FF0000">134 Stars</font>]</a >        
        <a href="https://huggingface.co/KyGao/FABind_plus_model">[Weights]</a>
    </li>

    <li>
        <a href='https://openreview.net/forum?id=iezDdA9oeB'> Fast and Accurate Blind Flexible Docking </a > <br>
        Zizhuo Zhang, Lijun Wu, <strong>Kaiyuan Gao</strong>, Jiangchao Yao, Tao Qin, Bo Han<br>
        International Conference on Learning Representations <strong>(ICLR 2025)</strong><br>
        <a href='https://github.com/QizhiPei/FABind'>[Code: <font color="#FF0000">134 Stars</font>]</a >        
        <a href="https://drive.google.com/drive/folders/1WXhDX1wuYrvtwwEZyZakAy5lxpNcQ0A5">[Weights]</a>
    </li>

    <li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3580305.3599468'> Pre-training antibody language models for antigen-specific computational antibody design </a > <br>
        <strong>Kaiyuan Gao</strong>, Lijun Wu, Jinhua Zhu, Tianbo Peng, Yingce Xia, Liang He, Shufang Xie, Tao Qin, Haiguang Liu, Kun He, Tie-Yan Liu<br>
        ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2023)</strong><br>
        <a href='https://github.com/KyGao/ABGNN'>[Code: 53 Stars]</a >        
        <a href="https://drive.google.com/file/d/1gKHsWUt_uqfFOKbhJDKln9M6gp4Z2xWa">[Weights]</a>
    </li>

    <li>
        <a href='https://dl.acm.org/doi/abs/10.1145/3711896.3736896'> CovDocker: Benchmarking Covalent Drug Design with Tasks, Datasets, and Solutions </a > <br>
        Yangzhe* Peng, <strong>Kaiyuan Gao*</strong>, Liang He, Yuheng Cong, Haiguang Liu, Kun He, Lijun Wu<br>
        ACM SIGKDD Conference on Knowledge Discovery and Data Mining <strong>(KDD 2025)</strong><br>
        <a href='https://github.com/PoloWitty/CovDocker'>[Code]</a >        
        <a href="https://zenodo.org/records/14738851">[Datasets]</a>
    </li>
</ul>

<strong> Multimodal Molecular Learning: </strong>
<ul>
    <li>
        <a href='https://arxiv.org/abs/2412.01564'> Tokenizing 3d molecule structure with quantized spherical coordinates </a > <br>
        <strong>Kaiyuan Gao</strong>, Yusong Wang, Haoxiang Guan, Zun Wang, Qizhi Pei, John E Hopcroft, Kun He, Lijun Wu<br>
    </li>

    <li>
        <a href='https://arxiv.org/abs/2310.07276'> 3D-MolT5: Towards Unified 3D Molecule-Text Modeling with 3D Molecular Tokenization </a > <br>
        Qizhi Pei, Lijun Wu, <strong>Kaiyuan Gao</strong>, Jinhua Zhu, Rui Yan<br>
        International Conference on Learning Representations <strong>(ICLR 2025)</strong>
    </li>

    <li>
        <a href='https://arxiv.org/abs/2310.07276'> Biot5: Enriching cross-modal integration in biology with chemical knowledge and natural language associations </a > <br>
        Qizhi Pei, Wei Zhang, Jinhua Zhu, Kehan Wu, <strong>Kaiyuan Gao</strong>, Lijun Wu, Yingce Xia, Rui Yan<br>
        Empirical Methods in Natural Language Processing 2023 <strong>(EMNLP 2023)</strong><br>
        <a href='https://github.com/QizhiPei/BioT5'>[Code: <font color="#FF0000">118 Stars</font>]</a >    
        <a href="https://huggingface.co/QizhiPei/biot5-base">[Weights]</a>
    </li>

    <li>
        <a href='https://arxiv.org/abs/2402.17810'> Biot5+: Towards generalized biological understanding with iupac integration and multi-task tuning </a > <br>
        Qizhi Pei, Lijun Wu, <strong>Kaiyuan Gao</strong>, Xiaozhuan Liang, Yin Fang, Jinhua Zhu, Shufang Xie, Tao Qin, Rui Yan<br>
        The Association for Computational Linguistics <strong>(ACL 2024 (Findings))</strong><br>
        <a href='https://github.com/QizhiPei/BioT5'>[Code: <font color="#FF0000">118 Stars</font>]</a >    
        <a href="https://huggingface.co/QizhiPei/biot5-plus-base">[Weights]</a>
    </li>

    <li>
        <a href='https://arxiv.org/abs/2502.07527'> Naturelm: Deciphering the language of nature for scientific discovery </a > <br>
        Yingce Xia, Peiran Jin, Shufang Xie, Liang He, Chuan Cao, Renqian Luo, Guoqing Liu, Yue Wang, Zequn Liu, Yuan-Jyue Chen, Zekun Guo, Yeqi Bai, Pan Deng, Yaosen Min, Ziheng Lu, Hongxia Hao, Han Yang, Jielan Li, Chang Liu, Jia Zhang, Jianwei Zhu, Kehan Wu, Wei Zhang, <strong>Kaiyuan Gao</strong>, Qizhi Pei, Qian Wang, Xixian Liu, Yanting Li, Houtian Zhu, Yeqing Lu, Mingqian Ma, Zun Wang, Tian Xie, Krzysztof Maziarz, Marwin Segler, Zhao Yang, Zilong Chen, Yu Shi, Shuxin Zheng, Lijun Wu, Chen Hu, Peggy Dai, Tie-Yan Liu, Haiguang Liu, Tao Qin<br>
        <a href="https://naturelm.github.io">[Project Page]</a>
        <a href="https://github.com/microsoft/SFM">[Code]</a>
        <a href="https://huggingface.co/collections/microsoft/naturelm-685142a78ede3cd04391af4f">[Weights]</a>
    </li>
</ul>

<strong> Graph Learning: </strong>
<ul>
    <li>
        <a href='https://openreview.net/pdf?id=8KYeilT3Ow'> NAGphormer: A tokenized graph transformer for node classification in large graphs </a > <br>
        Jinsong Chen*, <strong>Kaiyuan Gao*</strong>, Gaichao Li, Kun He<br>
        International Conference on Learning Representations <strong>(ICLR 2022)</strong><br>
        <a href='https://github.com/JHL-HUST/NAGphormer'>[Code: <font color="#FF0000">129 Stars</font>]</a >        
    </li>

        <li>
        <a href='https://ieeexplore.ieee.org/abstract/document/10818575'> Nagphormer+: A tokenized graph transformer with neighborhood augmentation for node classification in large graphs </a > <br>
        Jinsong Chen*, <strong>Kaiyuan Gao*</strong>, Gaichao Li, Kun He<br>
        IEEE Transactions on Big Data <strong>(TBD)</strong>
    </li>
</ul>

    
    

<!-- * indicates co-first authors. -->

<!-- <h2>Selected Honors & Awards</h2>
<ul>
    <li>
        <strong>
            Outstanding Doctoral Thesis, Tsinghua University
        </strong>, 2024.06
    </li>
    <li>
        <strong>
            <a href="https://jw.beijing.gov.cn/tzgg/202401/t20240102_3522508.html">Beijing Outstanding Graduates</a >
        </strong>, 2024.01
    </li>
    <li>
        <strong>
            <a href="https://www.cs.tsinghua.edu.cn/info/1088/5784.htm">Zhong Shimo Scholarship</a >
        </strong>, 2023.12
    </li>
    <li>
        <strong>
            <a href="https://www.cs.tsinghua.edu.cn/info/1088/5784.htm">China National Scholarship</a >
        </strong>, 2023.12
    </li>
    <li>
        <strong>
            <a href="https://ur.bytedance.com/scholarship">ByteDance Scholarship</a >
        </strong>, 2023.10
    </li>
    <li>
        <strong>'84' Future Innovation Scholarship, Tsinghua University</strong>, 2020.12
    </li>
    <li>
        <strong>Top Ten Compus Singers Competition, Tsinghua University</strong>, 2019.10
    </li>
    <li>
        <strong>Outstanding Graduates, Department of Computer Science and Technology, Tsinghua University</strong>, 2019.06
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Meritorious Winner</strong>, 2018
    </li>
    <li>
        <strong>Chinese Mathematical Olympiad (CMO), Silver Medal</strong>, 2014
    </li>
</ul> -->


<!-- <h2>Services</h2>
<h3>Reviewer</h3>
    <strong>NeurIPS</strong> (2021, 2022 with <strong><a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewer</a ></strong>, <a href="https://score-based-methods-workshop.github.io/">2022 workshop</a >); <strong>ICML</strong> (2021-2024); <strong>ICLR</strong> (2021, 2023-2024); <strong>CVPR</strong> (2023-2024); <strong>ICCV</strong> 2023; <strong>ECCV</strong> 2024; <strong>IJCV</strong>;

<h3> Contributor</h3>
    <strong><a href="https://github.com/huggingface/diffusers">huggingface/diffusers</a ></strong>, the most widely-used library for diffusion models.


<h3>Teaching</h3>
2021 Spring, Head TA in <strong>Statistical Learning Theory and Applications</strong>, instructed by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a ><br>
2021 Spring, TA in <strong>Deep Learning</strong>, instructed by <a href="http://www.xlhu.cn/">Prof. Xiaolin Hu</a > and <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a ><br> -->

</div>

<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2025 Kaiyuan Gao

</body>

</html>